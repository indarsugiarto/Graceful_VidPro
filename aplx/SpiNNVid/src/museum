

/*--------------------------------------------------------------------------------------*/
/*--------------------------------------------------------------------------------------*/
/*--------------------------------------------------------------------------------------*/
/*-------------------- MUSEUM: from previously failed algorithm ------------------------*/
/*                                                                                      */
/* Note: we cannot broadcast the sdp address because IT IS LOCAL DTCM !!!               */
/*                                                                                      */
/*--------------------------------------------------------------------------------------*/
/*--------------------------------------------------------------------------------------*/
/*--------------------------------------------------------------------------------------*/

/*
// TODO: when do you put the chunk data into sdram?

// storeFrame: call dma for dtcmImgBuf and reset its counter
void storeDtcmImgBuf(uint ch, uint Unused)
{
	uchar *dest;
	switch(ch) {
	case 0:
		dest = blkInfo->imgRIn; blkInfo->imgRIn += pixelCntr; break;
	case 1:
		dest = blkInfo->imgGIn; blkInfo->imgGIn += pixelCntr; break;
	case 2:
		dest = blkInfo->imgBIn; blkInfo->imgBIn += pixelCntr; break;
	}

	spin1_dma_transfer(DMA_TAG_STORE_FRAME, dest, dtcmImgBuf, DMA_WRITE, pixelCntr);

	// then adjust/correct the pointer and the counter
	pixelCntr = 0;
}

/*--------------------------------------------------------------------------------------*
/*-------------------- leadAp forward sdp buffer to core 2,3 and 4 ---------------------*
/*                                                                                      *
/* processImgData() is executed by core-2,3 and 4 only in root node as a response to
 * MCPL with keys MCPL_PROCEED_?_IMG_DATA triggered by leadAp after receiving sdp for
 * frames (through specif frame's port
 * *
void processImgData(uint mBox, uint ch) {
    io_printf(IO_STD, "processImgData with ch-%d is triggered\n", ch);

	sdp_msg_t *msg = (sdp_msg_t *)mBox;
	ushort pxLen = msg->length - sizeof(sdp_hdr_t);

	io_printf(IO_BUF, "in process: got mBox at-0x%x with pxLen=%d\n", msg, pxLen);

	return;

	// step-1: copy the content of mBox to local buffer
	uchar pxInfo[272];
	sark_mem_cpy((void *)pxInfo, (void *)&msg->cmd_rc, pxLen);
	io_printf(IO_BUF, "sdp data is copied...\n");



	// step-2: then release mBox
	spin1_msg_free(msg);
	io_printf(IO_BUF, "sdp is release...\n");



	// step-3: copy to dtcmImgBuf and if necessary trigger dma
	sark_mem_cpy((void *)dtcmImgBuf+pixelCntr, pxInfo, pxLen);
	io_printf(IO_BUF, "copied to dtcmImgBuf...\n");
	pixelCntr += pxLen;
	if(pixelCntr==workers.wImg) {
		spin1_schedule_callback(storeDtcmImgBuf, ch, 0, PRIORITY_PROCESSING);
	}
	// then forward to other nodes
	uchar i, cntr;
	uint payload, base_key, key;

	cntr = (pxLen % 4) == 0 ? pxLen / 4 : (pxLen / 4) + 1;

	switch(ch) {
	case 0: base_key = MCPL_FWD_R_IMG_DATA; break;
	case 1: base_key = MCPL_FWD_G_IMG_DATA; break;
	case 2: base_key = MCPL_FWD_B_IMG_DATA; break;
	}

	ushort szpx, remaining = pxLen;
	for(i=0; i<cntr; i++) {
		if(remaining > sizeof(uint))
			szpx = sizeof(uint);
		else
			szpx = remaining;
		sark_mem_cpy((void *)&payload, (void *)pxInfo + i*4, szpx);

		//key = base_key | (cntr << 8) | i; // we have problem with this scheme
											// because we also need to put the pxLen, but where?
											// solution: assuming MCPL never race!!!

		// the key will contains which channel (base_key), total length of current packet (pxLen)
		// and current length of the chunk (szpx)
		key = base_key | (pxLen << 4) | szpx;
		spin1_send_mc_packet(key, payload, WITH_PAYLOAD);

		remaining -= szpx;

		// for debugging, remove in release mode:
		io_printf(IO_BUF, "key-0x%x load-0x%x has been sent!\n", key, payload);
		sark_delay_us(1000);
	}

	// TODO: decompress data
	// decompress(ch);
	// then reset buffer for next delivery
}



/*--------------------------------------------------------------------------------------*
/*------- core 2,3 and 4 in other nodes (out of root node) receive fwd-ed packets ------*
/*                                                                                      *
/* recvFwdImgData() is executed by core-2,3 and 4 in nodes other than root. It processes
 * forwarded packets from core-2,3 and 4 in root node *
void recvFwdImgData(uint pxData, uint pxLenCh)
{
	io_printf(IO_BUF, "recvFwdImgData is triggered\n");
	uchar  ch = pxLenCh >> 16;
	ushort pxLen = (pxLenCh & 0xFFFF) >> 4;
	uchar  szpx = pxLenCh & 0xF;

	sark_mem_cpy((void *)fwdPktBuffer[ch].pxInfo+fwdPktBuffer[ch].pxLen, (void *)&pxData, szpx);

	fwdPktBuffer[ch].pxLen += szpx;

	// all chunks are collected?
	if(fwdPktBuffer[ch].pxLen == pxLen) {

		// for debugging:
		io_printf(IO_BUF, "Core-%d has received the chunk!\n", myCoreID);

		// put to dtcmImgBuf
		sark_mem_cpy((void *)dtcmImgBuf+pixelCntr, (void *)fwdPktBuffer[ch].pxInfo, pxLen);

		pixelCntr += pxLen;

		if(pixelCntr==workers.wImg)
			spin1_schedule_callback(storeDtcmImgBuf, ch, 0, PRIORITY_PROCESSING);

		// TODO: decompress data
		// decompress(ch);
		// reset the counter for next delivery
		fwdPktBuffer[ch].pxLen = 0;
	}
}



void decompress(uchar ch)
{

}

*/

/*--------------------------------------------------------------------------------------*/
/*-------------------- MUSEUM: from previously failed algorithm ------------------------*/
/*--------------------------------------------------------------------------------------*/
/*--------------------------------------------------------------------------------------*/




___________________________________________________________________________________________








void imgDetection(uint arg0, uint arg1)
{
	// debugging:
	io_printf(IO_BUF, "Start edge detection\n");
	//io_printf(IO_BUF, "Begin edge detection...\n");
	ushort offset = workers.opType == IMG_SOBEL ? 1:2;
	offset *= workers.wImg;

	short l,c,n,i,j;
	uchar *sdramImgIn, *sdramImgOut;
	uchar *dtcmLine;	//point to the current image line in the DTCM (not in SDRAM!)
	int sumX, sumY, sumXY;

	uint adj;

	uint dmatag;

	// how many lines this worker has?
	n = workers.endLine - workers.startLine + 1;

	// io_printf(IO_BUF, "n = %d\n", n);

	// prepare the correct line address in sdram
	if(workers.opFilter==IMG_WITHOUT_FILTER) {
		sdramImgIn = workers.imgOut1;
		sdramImgOut = workers.imgOut2;
	} else {
		sdramImgIn = workers.imgOut2;
		sdramImgOut = workers.imgOut3;
	}
	/*
	io_printf(IO_BUF, "dtcmImgBuf = 0x%x\n", dtcmImgBuf);
	io_printf(IO_BUF, "resImgBuf = 0x%x\n", resImgBuf);
	io_printf(IO_BUF, "workers.wImg = %d = 0x%x\n", workers.wImg, workers.wImg);
	io_printf(IO_BUF, "workers.imgOut1 = 0x%x\n", workers.imgOut1);
	io_printf(IO_BUF, "workers.imgOut2 = 0x%x\n", workers.imgOut2);
	io_printf(IO_BUF, "workers.blkImgOut1 = 0x%x\n", workers.blkImgOut1);
	io_printf(IO_BUF, "workers.blkImgOut2 = 0x%x\n-----------------------------\n",
			  workers.blkImgOut2);
	*/
	// scan for all lines in the working block
	for(l=0; l<n; l++) {
		// io_printf(IO_BUF, "sdramImgIn = 0x%x, sdramImgOut = 0x%x\n", sdramImgIn, sdramImgOut);
		// adjust pointer for each line
		/*
		adj = l*workers.wImg;
		sdramImgIn += adj;
		sdramImgOut += adj;
		*/

		// shift by mask size for fetching via dma
		//sdramImgIn -= offset*workers.wImg;
		//sdramImgIn -= offset;

		dmaImgFromSDRAMdone = 0;
		dmatag = DMA_FETCH_IMG_TAG | (myCoreID << 16);
		do {
			/**/
			dmaTID = spin1_dma_transfer(dmatag, (void *)sdramImgIn - offset,
										(void *)dtcmImgBuf, DMA_READ, workers.szDtcmImgBuf);
			/**/
			/*
			dmaTID = spin1_dma_transfer(dmatag, (void *)sdramImgIn,
										(void *)dtcmImgBuf, DMA_READ, workers.szDtcmImgBuf);
			*/
			if(dmaTID==0)
				io_printf(IO_BUF, "[Edging] DMA full for tag-0x%x! Retry...\n", dmatag);
		} while (dmaTID==0);

		// wait until dma above is completed
		while(dmaImgFromSDRAMdone==0) {
		}

		// point to the current image line in the DTCM (not in SDRAM!)
		// mind the offset since dtcmImgBuf contains additional data
		//dtcmLine = dtcmImgBuf + offset*workers.wImg;
		dtcmLine = dtcmImgBuf + offset;

		// scan for all column in the line
		for(c=0; c<workers.wImg; c++) {
			// if offset is 1, then it is for sobel, otherwise it is for laplace
			if(offset==1) {
				sumX = 0;
				sumY = 0;
				if(workers.startLine+l == 0 || workers.startLine+l == workers.hImg-1)
					sumXY = 0;
				else if(c==0 || c==workers.wImg-1)
					sumXY = 0;
				else {
					for(i=-1; i<=1; i++)
						for(j=-1; j<=1; j++) {
							sumX += (int)((*(dtcmLine + c + i + j*workers.wImg)) * GX[i+1][j+1]);
							sumY += (int)((*(dtcmLine + c + i + j*workers.wImg)) * GY[i+1][j+1]);
						}
					// python version: sumXY[0] = math.sqrt(math.pow(sumX[0],2) + math.pow(sumY[0],2))
					sumXY = (abs(sumX) + abs(sumY))*7/10;	// 7/10 = 0.717 -> cukup dekat dengan akar
				}
			}
			else {	// for laplace operation
				sumXY = 0;
				if((workers.startLine+l) < 2 || (workers.hImg-workers.startLine+l) <= 2)
					sumXY = 0;
				else if(c<2 || (workers.wImg-c)<=2)
					sumXY = 0;
				else {
					for(i=-1; i<=2; i++)
						for(j=-2; j<=2; j++)
							sumXY += (int)((*(dtcmLine + c + i + j*workers.wImg)) * LAP[i+2][j+2]);
				}
			}

			// make necessary correction
			if(sumXY>255) sumXY = 255;
			if(sumXY<0) sumXY = 0;

			// resImgBuf is just one line and it doesn't matter, where it is!
			// *(resImgBuf + c) = 255 - (uchar)(sumXY);
			resImgBuf[c] = 255 - (uchar)(sumXY); // identik dengan yang di atas

			// *(resImgBuf + c) = (uchar)(sumXY);
			//dmaTID = spin1_dma_transfer((myCoreID << 16) + DMA_STORE_IMG_TAG, (void *)sdramImgOut,
			//			   (void *)resImgBuf, DMA_WRITE, workers.wImg);

		} // end for c-loop

		// then copy the resulting line into sdram

		dmatag = (myCoreID << 16) | DMA_STORE_IMG_TAG;
		do {
			dmaTID = spin1_dma_transfer(dmatag, (void *)sdramImgOut,
						   (void *)resImgBuf, DMA_WRITE, workers.wImg);
			if(dmaTID==0)
				io_printf(IO_BUF, "[Edging] DMA full for tag-0x%x! Retry...\n", dmatag);
		} while(dmaTID==0);


		// move to the next line
		sdramImgIn += workers.wImg;
		sdramImgOut += workers.wImg;


    } // end for l-loop

    // at the end, send MCPL_EDGE_DONE
    io_printf(IO_BUF, "Done! send MCPL_EDGE_DONE!\n");
    spin1_send_mc_packet(MCPL_EDGE_DONE, 0, WITH_PAYLOAD);
}


void imgDetection(uint arg0, uint arg1)
{
	//io_printf(IO_BUF, "Begin edge detection...\n");
	ushort szMask = blkInfo->opType == IMG_SOBEL ? 3:5;
	ushort offset = blkInfo->opType == IMG_SOBEL ? 1:2;

	ushort w = blkInfo->wImg;
	ushort h = blkInfo->hImg;
	uint cntPixel = szMask * w;
	short l,c,n,i,j;
	uchar *sdramImgIn, *sdramImgOut;
	uchar *dtcmLine;
	int sumX, sumY, sumXY;

	uchar *resImgBuf, *dtcmImgBuf;

	uint dmaCheck;

	uint dmatag;

	offset *= w;

	// how many lines this worker has?
	n = workers.endLine - workers.startLine + 1;
	// when first called, dtcmImgBuf should be NULL
	// and img*In must point to the BASE
	dtcmImgBuf = sark_alloc(cntPixel, sizeof(uchar));
	resImgBuf = sark_alloc(w, sizeof(uchar));	// just one line!


		// scan for all lines in the working block
		for(l=0; l<n; l++) {
			// get the current line address in sdram
			// prepare the correct line address in sdram
			if(workers.opFilter==IMG_WITHOUT_FILTER) {
				sdramImgIn = workers.imgOut1 + l*w;
				sdramImgOut = workers.imgOut2 + l*w;
			} else {
				sdramImgIn = workers.imgOut2 + l*w;
				sdramImgOut = workers.imgOut3 + l*w;
			}

			// shift by mask size for fetching via dma
			sdramImgIn -= offset;

			dmaImgFromSDRAMdone = 0;
			dmatag = (myCoreID << 16) +  DMA_FETCH_IMG_TAG;
			do {
				dmaCheck = spin1_dma_transfer(dmatag, (void *)sdramImgIn,
								   (void *)dtcmImgBuf, DMA_READ, cntPixel);
				if(dmaCheck==0)
					io_printf(IO_BUF, "[Edging] DMA full! Retry...\n");
			} while (dmaCheck==0);

			while(dmaImgFromSDRAMdone==0) {
			}

			// point to the current image line in the DTCM (not in SDRAM!)
			dtcmLine = dtcmImgBuf + offset;	// mind the offset since dtcmImgBuf contains additional data

			// scan for all column in the line
			for(c=0; c<w; c++) {
				// if offset is 1, then it is for sobel, otherwise it is for laplace
				if(offset==1) {
					sumX = 0;
					sumY = 0;
					if(workers.startLine+l == 0 || workers.startLine+l == h-1)
						sumXY = 0;
					else if(c==0 || c==w-1)
						sumXY = 0;
					else {
						for(i=-1; i<=1; i++)
							for(j=-1; j<=1; j++) {
								sumX += (int)((*(dtcmLine + c + i + j*w)) * GX[i+1][j+1]);
								sumY += (int)((*(dtcmLine + c + i + j*w)) * GY[i+1][j+1]);
							}
						// python version: sumXY[0] = math.sqrt(math.pow(sumX[0],2) + math.pow(sumY[0],2))
						sumXY = (abs(sumX) + abs(sumY))*7/10;	// 7/10 = 0.717 -> cukup dekat dengan akar
					}
				}
				else {	// for laplace operation
					sumXY = 0;
					if((workers.startLine+l) < 2 || (h-workers.startLine+l) <= 2)
						sumXY = 0;
					else if(c<2 || (w-c)<=2)
						sumXY = 0;
					else {
						for(i=-1; i<=2; i++)
							for(j=-2; j<=2; j++)
								sumXY += (int)((*(dtcmLine + c + i + j*w)) * LAP[i+2][j+2]);
					}
				}
				if(sumXY>255) sumXY = 255;
				if(sumXY<0) sumXY = 0;
				// resImgBuf is just one line and it doesn't matter, where it is!
				*(resImgBuf + c) = 255 - (uchar)(sumXY);
				//*(resImgBuf + c) = (uchar)(sumXY);
				// TODO: what if dma full?
				//spin1_dma_transfer((myCoreID << 16) + DMA_STORE_IMG_TAG, (void *)sdramImgOut,
				//				   (void *)resImgBuf, DMA_WRITE, w);
			} // end for c-loop
			dmatag = (myCoreID << 16) | DMA_STORE_IMG_TAG;
			do {
				dmaTID = spin1_dma_transfer(dmatag, (void *)sdramImgOut,
							   (void *)resImgBuf, DMA_WRITE, workers.wImg);
				if(dmaTID==0)
					io_printf(IO_BUF, "[Edging] DMA full for tag-0x%x! Retry...\n", dmatag);
			} while(dmaTID==0);

		} // end for l-loop

		/*
		// if img is grey, stop with R-channel only
		if(rgbCntr>=1 && blkInfo->isGrey==1)
			break;
		*/

    // clean-up memory in DTCM
    sark_free(resImgBuf);  //resImgBuf = NULL;
    sark_free(dtcmImgBuf); //dtcmImgBuf = NULL; // -> this will create WDOG!!!
    // at the end, send MCPL_EDGE_DONE
    // io_printf(IO_BUF, "Done! send MCPL_EDGE_DONE!\n");
    spin1_send_mc_packet(MCPL_EDGE_DONE, 0, WITH_PAYLOAD);
}

___________________________________________________________________________________________



void triggerProcessing(uint taskID, uint arg1)
{
	// prepare measurement
	tic = sv->clock_ms;

	// how many workers/blocks have finished the process?
	nEdgeJobDone = 0;
	perf.tEdgeNode = 0;
	perf.tEdgeTotal = 0;
	nBlockDone = 0;

	/*
	if(blkInfo->opSharpen==1) {
		proc = PROC_HISTEQ;
		// only if root-node and leadAp, trigger the histogram equalisation chain
		if(sv->p2p_addr==0 && leadAp)

			// start timer to measure time
			START_TIMER();

			spin1_send_mc_packet(MCPL_BCAST_REPORT_HIST, 0, WITH_PAYLOAD);
			// MCPL_BCAST_REPORT_HIST will be broadcasted to all cores in all chips
			// only core-1 to core-4 in all chips will response to this call, because
			// for sending 256 item of uint, we require 4 active "thread". Hence, we assign
			// 4 cores to do this.
	}
	else if(blkInfo->opFilter==1) {
		proc = PROC_FILTERING;
		imgFiltering(0,0);	// inside imgFiltering, it will then call imgDetection
	}
	else {
		proc = PROC_EDGING;
#if (adaptiveFreq==TRUE)
		//changeFreq(250);
		imgDetection(0,0);	// go edge detection directly
		//changeFreq(200);
#else
		imgDetection(0,0);	// go edge detection directly
#endif
	}

	*/
	proc = PROC_EDGING;
#if (adaptiveFreq==TRUE)
		//changeFreq(250);
		imgDetection(0,0);	// go edge detection directly
		//changeFreq(200);
#else
		imgDetection(0,0);	// go edge detection directly
#endif

	// then reset newImageFlag so that the next frame can be detected properly
	newImageFlag = TRUE;
}





___________________________________________________________________________________________

	// MCPL_BLOCK_DONE is deprecated
	else if(key==MCPL_BLOCK_DONE) {
		nBlockDone++;
		/*
		io_printf(IO_STD, "Receive MCPL_BLOCK_DONE from node-%d\n", payload);
		io_printf(IO_STD, "Total nBlockDone now is %d\n", nBlockDone);
		io_printf(IO_STD, "Next block should be %d\n", payload+1);
		*/
		if(nBlockDone==blkInfo->maxBlock) {
			spin1_schedule_callback(notifyDestDone, 0, 0, PRIORITY_PROCESSING);
		}
		// if I'm block-0, continue the chain by broadcasting to other nodes
		// with the next node-ID (++payload)
		// MCPL_BCAST_SEND_RESULT is destined to other external nodes from root-node
		else if(blkInfo->nodeBlockID==0) {
			spin1_send_mc_packet(MCPL_BCAST_SEND_RESULT, payload+1, WITH_PAYLOAD);
			//spin1_send_mc_packet(MCPL_BCAST_SEND_RESULT, ++payload, WITH_PAYLOAD);
		}
	}

___________________________________________________________________________________________



// AfterProcessingDone() is managed by the leadAp in each node.
// But in root-node, afterProcessingDone() will trigger sending the result.
void afterProcessingDone(uint arg0, uint arg1)
{
    if(proc==PROC_EDGING) {
#if (DEBUG_LEVEL > 0)
        // optional, won't be used in video streaming:
        io_printf(IO_BUF, "Node-%d is done edging in %d-ms!\n", blkInfo->nodeBlockID, elapse);
#endif
        // if root-node, trigger to send the result
        if(sv->p2p_addr==0) {
#if (DESTINATION==DEST_HOST)
            spin1_schedule_callback(sendDetectionResult2Host, 0, 0, PRIORITY_PROCESSING);
#elif (DESTINATION==DEST_FPGA)
            spin1_schedule_callback(sendDetectionResult2FPGA, 0, 0, PRIORITY_PROCESSING);
#endif
        }
    }
}

___________________________________________________________________________________________





/* initRouter() initialize MCPL routing table by leadCore. Normally, there are two keys:
 * MCPL_BCAST_KEY and MCPL_TO_LEADER
 * */
void initRouter()
{
	uint allRoute = 0xFFFF80;			// excluding core-0 and external links
	uint profiler = (1 << (PROF_CORE+6));
	uint leader = (1 << (LEAD_CORE+6));	// only for leadAp
	uint workers = allRoute & ~leader;	// for other workers in the chip
	workers &= (~profiler);				// exclude profiler
	allRoute &= (~profiler);				// exclude profiler
	uint key, dest;
	uint x, y, d, c;




	/*----------------------------------------------------------------------------*/
	/*----------------------------------------------------------------------------*/
	/*----------------------- keys for intra-chip routing ------------------------*/
	// first, set individual destination, assuming all 17-cores are available
	uint e = rtr_alloc(17);
	if(e==0) {
		terminate_SpiNNVid(IO_STD, "initRouter err for intra-chip!\n", RTE_ABORT);
	} else {
		// each destination core might have its own key association
		// so that leadAp can tell each worker, which region is their part
		for(uint i=0; i<17; i++)
			// starting from core-1 up to core-17
			rtr_mc_set(e+i, i+1, 0xFFFFFFFF, (MC_CORE_ROUTE(i+1)));
	}
	// other broadcasting keys
	e = rtr_alloc(6);
	if(e==0)
	{
		terminate_SpiNNVid(IO_STD, "initRouter err for intra-chip!\n", RTE_ABORT);
	} else {
		rtr_mc_set(e, MCPL_BCAST_INFO_KEY,	0xFFFFFFFF, workers);	e++;
		rtr_mc_set(e, MCPL_PING_REPLY,		0xFFFFFFFF, leader);	e++;
		rtr_mc_set(e, MCPL_BCAST_GET_WLOAD, 0xFFFFFFFF, allRoute);	e++;
		rtr_mc_set(e, MCPL_EDGE_DONE,		0xFFFFFFFF, leader);	e++;
		rtr_mc_set(e, MCPL_FILT_DONE,		0xFFFFFFFF, leader);	e++;
		rtr_mc_set(e, MCPL_REPORT_HIST2LEAD, MCPL_REPORT_HIST2LEAD_MASK, leader); e++;
	}




	/*----------------------------------------------------------------------------*/
	/*----------------------------------------------------------------------------*/
	/*----------------------- keys for inter-chip routing ------------------------*/
	x = CHIP_X(sv->p2p_addr);
	y = CHIP_Y(sv->p2p_addr);

	// broadcasting from root node like:
	// MCPL_BCAST_SEND_RESULT, MCPL_BCAST_RESET_NET, etc
	dest = leader;	// by default, go to leadAP, unless:
#if(USING_SPIN==5)
	if(x==y) {
		if(x==0)
			dest = 1 + (1 << 1) + (1 << 2);
		else if(x<7)
			dest += 1 + (1 << 1) + (1 << 2);
	}
	else if(x>y) {
		d = x - y;
		if(x<7 && d<4)
			dest += 1;
	}
	else if(x<y) {
		d = y - x;
		if(d<3 && y<7)
			dest += (1 << 2);
	}
#elif(USING_SPIN==3)
	if(sv->p2p_addr==0)
		dest = 1 + (1<<1) + (1<<2);
#endif
	e = rtr_alloc(6);
	if(e==0)
	{
		terminate_SpiNNVid(IO_STD, "initRouter err for inter-chip!\n", RTE_ABORT);
	} else {
		rtr_mc_set(e, MCPL_BCAST_NODES_INFO,	0xFFFFFFFF, dest); e++;
		rtr_mc_set(e, MCPL_BCAST_OP_INFO,		0xFFFFFFFF, dest); e++;
		rtr_mc_set(e, MCPL_BCAST_FRAME_INFO,	0xFFFFFFFF, dest); e++;
		//rtr_mc_set(e, MCPL_BCAST_SEND_RESULT,	0xFFFFFFFF, dest); e++;
		rtr_mc_set(e, MCPL_BCAST_RESET_NET,		0xFFFFFFFF, dest); e++;
		rtr_mc_set(e, MCPL_BCAST_NET_DISCOVERY, 0xFFFFFFFF, dest); e++;
	}

	// special for MCPL_BLOCK_DONE
	// this is for sending toward core <0,0,leadAp>
	if (x>0 && y>0)			dest = (1 << 4);	// south-west
	else if(x>0 && y==0)	dest = (1 << 3);	// west
	else if(x==0 && y>0)	dest = (1 << 5);	// south
	else					dest = leader;
	e = rtr_alloc(5);
	if(e==0)
	{
		terminate_SpiNNVid(IO_STD, "initRouter err for special keys!\n", RTE_ABORT);
	} else {
		//rtr_mc_set(e, MCPL_BLOCK_DONE, 0xFFFFFFFF, dest); e++;
		rtr_mc_set(e, MCPL_BLOCK_DONE_TEDGE,	0xFFFF0000, dest); e++;
		rtr_mc_set(e, MCPL_BLOCK_DONE_TFILT,	0xFFFF0000, dest); e++;
		rtr_mc_set(e, MCPL_RECV_END_OF_FRAME,	0xFFFF0000, dest); e++;
		rtr_mc_set(e, MCPL_IGNORE_END_OF_FRAME, 0xFFFFFFFF, workers); e++;
		rtr_mc_set(e, MCPL_BCAST_NET_REPLY,		0xFFFFFFFF, dest); e++;
	}




	/*----------------------------------------------------------------------------*/
	/*----------------------------------------------------------------------------*/
	/*------------------------ keys for forwarding pixels ------------------------*/
	dest = allRoute;
#if(USING_SPIN==5)
	if(x==y) {
		if(x<7)
			dest += 1 + (1 << 1) + (1 << 2);
	}
	else if(x>y) {
		d = x - y;
		if(x<7 && d<4)
			dest += 1;
	}
	else if(x<y) {
		d = y - x;
		if(d<3 && y<7)
			dest += (1 << 2);
	}
#elif(USING_SPIN==3)
	if(sv->p2p_addr==0)
		dest = 1 + (1<<1) + (1<<2);
#endif
	e = rtr_alloc(6);
	if(e==0)
	{
		terminate_SpiNNVid(IO_STD, "initRouter err for pixel forwarding!\n", RTE_ABORT);
	} else {
		rtr_mc_set(e, MCPL_FWD_PIXEL_INFO,	MCPL_FWD_PIXEL_MASK, dest); e++;
		rtr_mc_set(e, MCPL_FWD_PIXEL_RDATA, MCPL_FWD_PIXEL_MASK, dest); e++;
		rtr_mc_set(e, MCPL_FWD_PIXEL_GDATA, MCPL_FWD_PIXEL_MASK, dest); e++;
		rtr_mc_set(e, MCPL_FWD_PIXEL_BDATA, MCPL_FWD_PIXEL_MASK, dest); e++;
		rtr_mc_set(e, MCPL_FWD_PIXEL_YDATA, MCPL_FWD_PIXEL_MASK, dest); e++;
		rtr_mc_set(e, MCPL_FWD_PIXEL_EOF,	MCPL_FWD_PIXEL_MASK, dest); e++;
	}




	/*----------------------------------------------------------------------------*/
	/*----------------------------------------------------------------------------*/
	/*------------------------- keys for all routing -----------------------------*/
	dest = allRoute;
#if(USING_SPIN==5)
	if(x==y) {
		if(x<7)
			dest += 1 + (1 << 1) + (1 << 2);
	}
	else if(x>y) {
		d = x - y;
		if(x<7 && d<4)
			dest += 1;
	}
	else if(x<y) {
		d = y - x;
		if(d<3 && y<7)
			dest += (1 << 2);
	}
#elif(USING_SPIN==3)
	if(sv->p2p_addr==0)
		dest += 1 + (1<<1) + (1<<2);
#endif
	e = rtr_alloc(4);
	if(e==0)
	{
		terminate_SpiNNVid(IO_STD, "initRouter err for all-routing!\n", RTE_ABORT);
	} else {
		rtr_mc_set(e, MCPL_BCAST_ALL_REPORT, 0xFFFFFFFF, dest); e++;
		rtr_mc_set(e, MCPL_BCAST_START_PROC, 0xFFFFFFFF, dest); e++;
		// regarding histogram equalization
		rtr_mc_set(e, MCPL_BCAST_REPORT_HIST, MCPL_BCAST_REPORT_HIST_MASK, dest); e++;
		rtr_mc_set(e, MCPL_BCAST_HIST_RESULT, MCPL_BCAST_HIST_RESULT_MASK, dest); e++;
	}




	/*----------------------------------------------------------------------------*/
	/*----------------------------------------------------------------------------*/
	/*----------------- keys for sending result using buffering ------------------*/
	// key type-1: from leadAp-root to its own workers
	//if(blkInfo->nodeBlockID == 0) { // -> nodeBlockID is not available during this init()!!!!
	if(sv->p2p_addr == 0) {
		e = rtr_alloc(1);
		dest = allRoute;
		rtr_mc_set(e, MCPL_SEND_PIXELS_BLOCK_PREP, MCPL_SEND_PIXELS_BLOCK_MASK, dest); e++;
	}

	// key type-2: from the leadAp-root to other leadAps
	e = rtr_alloc(1);
	dest = leader;
#if(USING_SPIN==5)
	if(x==y) {
		if(x==0)
			dest = 1 + (1 << 1) + (1 << 2);
		else if(x<7)
			dest += 1 + (1 << 1) + (1 << 2);
	}
	else if(x>y) {
		d = x - y;
		if(x<7 && d<4)
			dest += 1;
	}
	else if(x<y) {
		d = y - x;
		if(d<3 && y<7)
			dest += (1 << 2);
	}
#elif(USING_SPIN==3)
	if(sv->p2p_addr==0)
		dest = 1 + (1<<1) + (1<<2);
#endif
	rtr_mc_set(e, MCPL_SEND_PIXELS_BLOCK, MCPL_SEND_PIXELS_BLOCK_MASK, dest); e++;

	// key type-3: from the leadAp to workers
	e = rtr_alloc(1);
	dest = allRoute;
	rtr_mc_set(e, MCPL_SEND_PIXELS_BLOCK_CORES, MCPL_SEND_PIXELS_BLOCK_MASK, dest); e++;

	// key type-4: from worker to its leadAp
	e = rtr_alloc(1);
	dest = (1 << LEAD_CORE+6);	// equal to dest = leader;
	rtr_mc_set(e, MCPL_SEND_PIXELS_BLOCK_CORES_DONE, MCPL_SEND_PIXELS_BLOCK_MASK, dest); e++;

	// key type-5: from non-root-cores to root-cores
	e = rtr_alloc(16);
	for(c=2; c<=17; c++) {
		key = MCPL_SEND_PIXELS_BLOCK_CORES_DATA | (c << 16);
		// this is for sending toward core <0,0,leadAp>
		if (x>0 && y>0)			dest = (1 << 4);	// south-west
		else if(x>0 && y==0)	dest = (1 << 3);	// west
		else if(x==0 && y>0)	dest = (1 << 5);	// south
		else					dest = 1 << (6+c);
		rtr_mc_set(e, key, MCPL_SEND_PIXELS_BLOCK_MASK, dest); e++;
	}

	// key type-6: from root-cores to non-root-cores
	e = rtr_alloc(16);
	for(c=2; c<=17; c++) {
		dest = 1 << (6+c);
#if(USING_SPIN==5)
		if(x==y) {
			if(x==0)
				dest = 1 + (1 << 1) + (1 << 2);
			else if(x<7)
				dest += 1 + (1 << 1) + (1 << 2);
		}
		else if(x>y) {
			d = x - y;
			if(x<7 && d<4)
				dest += 1;
		}
		else if(x<y) {
			d = y - x;
			if(d<3 && y<7)
				dest += (1 << 2);
		}
#elif(USING_SPIN==3)
		if(sv->p2p_addr==0)
			dest = 1 + (1<<1) + (1<<2);
#endif
		key = MCPL_SEND_PIXELS_BLOCK_CORES_NEXT | (c << 16);
		rtr_mc_set(e, key, MCPL_SEND_PIXELS_BLOCK_MASK, dest); e++;
	}

	// key type-7: from node-leadAp to root-leadAp
	e = rtr_alloc(1);
	// this is for sending toward core <0,0,leadAp>
	if (x>0 && y>0)			dest = (1 << 4);	// south-west
	else if(x>0 && y==0)	dest = (1 << 3);	// west
	else if(x==0 && y>0)	dest = (1 << 5);	// south
	else					dest = leader;
	rtr_mc_set(e, MCPL_SEND_PIXELS_BLOCK_DONE, MCPL_SEND_PIXELS_BLOCK_MASK, dest); e++;

	// key type-8: tell the streamer to start streamout
	if(sv->p2p_addr==0) {
		e = rtr_alloc(3);
		dest = 1 << (STREAMER_CORE + 6);
		rtr_mc_set(e, MCPL_SEND_PIXELS_BLOCK_GO_STREAMER, MCPL_SEND_PIXELS_BLOCK_MASK, dest); e++;
		rtr_mc_set(e, MCPL_SEND_PIXELS_BLOCK_INFO_STREAMER_SZIMG, MCPL_SEND_PIXELS_BLOCK_MASK, dest); e++;
		rtr_mc_set(e, MCPL_SEND_PIXELS_BLOCK_INFO_STREAMER_DEL, MCPL_SEND_PIXELS_BLOCK_MASK, dest); e++;
	}

	/*----------------------------------------------------------------------------*/
	/*----------------------------------------------------------------------------*/
	/*----------------------- other keys with special routing --------------------*/

	// communication with the profiler:
	// 1. all profilers:
	// 2. internal profiler:
	dest = profiler;
#if(USING_SPIN==5)
	if(x==y) {
		if(x<7)
			dest += 1 + (1 << 1) + (1 << 2);
	}
	else if(x>y) {
		d = x - y;
		if(x<7 && d<4)
			dest += 1;
	}
	else if(x<y) {
		d = y - x;
		if(d<3 && y<7)
			dest += (1 << 2);
	}
#elif(USING_SPIN==3)
	if(sv->p2p_addr==0)
		dest += 1 + (1 << 1) + (1 << 2);
#endif
	e = rtr_alloc(2);
	if(e==0)
	{
		terminate_SpiNNVid(IO_STD, "initRouter err for other keys!\n", RTE_ABORT);
	} else {
		rtr_mc_set(e, MCPL_TO_ALL_PROFILER,	0xFFFFFFFF, dest); e++;
		rtr_mc_set(e, MCPL_TO_OWN_PROFILER, 0xFFFFFFFF, profiler); e++;
	}
}


___________________________________________________________________________________________


